---
  hide:
    -navigation
---

## International Conferences

1. Chatzilygeroudis, K. and Vrahatis, M. 2023. **Fast and Robust Constrained Optimization via Evolutionary and Quadratic Programming**. *The 17th learning and intelligent optimization conference (LION).*

   **Abstract:** *Many efficient and effective approaches have been proposed in the evolutionary computation literature for solving constrained optimization problems. Most of the approaches assume that both the objective function and the constraints are black-box functions, while a few of them can take advantage of the gradient information. On the other hand, when the gradient information is available, the most versatile approaches are arguably the ones coming from the numerical optimization literature. Perhaps the most popular methods in this field are sequential quadratic programming and interior point. Despite their success, those methods require accurate gradients and usually require a well-shaped initialization to work as expected. In the paper at hand, a novel hybrid method, named UPSO-QP, is presented that is based on particle swarm optimization and borrows ideas from the numerical optimization literature and sequential quadratic programming approaches. The proposed method is evaluated on numerous constrained optimization tasks from simple low dimensional problems to high dimensional realistic trajectory optimization scenarios, and showcase that is able to outperform other evolutionary algorithms both in terms of convergence speed as well as performance, while also being robust to noisy gradients and bad initialization.*

   [(view online)](http://costashatz.github.io/files/LION17.pdf)

## Peer-Reviewed Workshops

1. Totsila, D.\*, Chatzilygeroudis, K.\*, Hadjivelichkov, D., Modugno, V., Hatzilygeroudis, I. and Kanoulas, D., 2023. **End-to-End Stable Imitation Learning via Autonomous Neural Dynamic Policies**. *IEEE International Conference on Robotics and Automation (ICRA), Life-Long Learning with Human Help (L3H2) Workshop*

   **Abstract:** *State-of-the-art sensorimotor learning algorithms offer policies that can often produce unstable behaviors, damaging the robot and/or the environment. Traditional robot learning, on the contrary, relies on dynamical system-based policies that can be analyzed for stability/safety. Such policies, however, are neither flexible nor generic and usually work only with proprioceptive sensor states. In this work, we bridge the gap between generic neural network policies and dynamical system-based policies, and we introduce Autonomous Neural Dynamic Policies (ANDPs) that: (a) are based on autonomous dynamical systems, (b) always produce asymptotically stable behaviors, and (c) are more flexible than traditional stable dynamical system-based policies. ANDPs are fully differentiable, flexible generic-policies that can be used in imitation learning setups while ensuring asymptotic stability. In this paper, we explore the flexibility and capacity of ANDPs in several imitation learning tasks including experiments with image observations. The results show that ANDPs combine the benefits of both neural network-based and dynamical system-based methods.*

   *\* Equal Contribution*

   [(view online)](https://arxiv.org/abs/2305.12886)
   [(poster)](files/2023-ICRA-L3H2-Poster-ANDPs.pdf)
